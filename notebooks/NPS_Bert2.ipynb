{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Workforce</th>\n",
       "      <th>NPS® Breakdown</th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "      <th>NPSCommentLemmatised</th>\n",
       "      <th>NPSCommentPolarity</th>\n",
       "      <th>NPSCommentSubjectivity</th>\n",
       "      <th>OverallCommentCleaned</th>\n",
       "      <th>OverallCommentLemmatised</th>\n",
       "      <th>OverallCommentPolarity</th>\n",
       "      <th>OverallCommentSubjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7053157</th>\n",
       "      <td>1763</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>staff in store in person close by when need them</td>\n",
       "      <td>Staff in store, in person, close by when I nee...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>was told the issue is more related to gmail th...</td>\n",
       "      <td>Was told the issue is more related to gmail th...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984308</th>\n",
       "      <td>832</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>adieb anbari was beyond helpful he answered al...</td>\n",
       "      <td>Adieb Anbari was beyond helpful . He answered ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>adieb was great would recommend him to help an...</td>\n",
       "      <td>Adieb was great I would recommend him to help ...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6980586</th>\n",
       "      <td>288</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>quick and knowledgeable</td>\n",
       "      <td>Quick and knowledgeable</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789897</th>\n",
       "      <td>168</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>he called back quickly within minutes and was ...</td>\n",
       "      <td>He called back quickly (within 5 minutes) and ...</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>appreciate his quick and knowledgeable response</td>\n",
       "      <td>Appreciate his quick and knowledgeable response.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896172</th>\n",
       "      <td>836</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>had really good experience thanks to your tech...</td>\n",
       "      <td>I had a really good experience thanks to your ...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>ricky finished with his prior appt so he took ...</td>\n",
       "      <td>Ricky finished with his prior appt so he took ...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Location Workforce NPS® Breakdown  NPS_Code  \\\n",
       "respid2                                                \n",
       "7053157      1763  Precinct       Promoter         2   \n",
       "6984308       832  Precinct       Promoter         2   \n",
       "6980586       288  Precinct       Promoter         2   \n",
       "6789897       168  Precinct       Promoter         2   \n",
       "6896172       836  Precinct       Promoter         2   \n",
       "\n",
       "                                         NPSCommentCleaned  \\\n",
       "respid2                                                      \n",
       "7053157   staff in store in person close by when need them   \n",
       "6984308  adieb anbari was beyond helpful he answered al...   \n",
       "6980586                            quick and knowledgeable   \n",
       "6789897  he called back quickly within minutes and was ...   \n",
       "6896172  had really good experience thanks to your tech...   \n",
       "\n",
       "                                      NPSCommentLemmatised  \\\n",
       "respid2                                                      \n",
       "7053157  Staff in store, in person, close by when I nee...   \n",
       "6984308  Adieb Anbari was beyond helpful . He answered ...   \n",
       "6980586                            Quick and knowledgeable   \n",
       "6789897  He called back quickly (within 5 minutes) and ...   \n",
       "6896172  I had a really good experience thanks to your ...   \n",
       "\n",
       "         NPSCommentPolarity  NPSCommentSubjectivity  \\\n",
       "respid2                                               \n",
       "7053157            0.000000                0.000000   \n",
       "6984308            0.100000                0.600000   \n",
       "6980586            0.333333                0.500000   \n",
       "6789897            0.414444                0.426667   \n",
       "6896172            0.450000                0.400000   \n",
       "\n",
       "                                     OverallCommentCleaned  \\\n",
       "respid2                                                      \n",
       "7053157  was told the issue is more related to gmail th...   \n",
       "6984308  adieb was great would recommend him to help an...   \n",
       "6980586                                             xyxyxz   \n",
       "6789897    appreciate his quick and knowledgeable response   \n",
       "6896172  ricky finished with his prior appt so he took ...   \n",
       "\n",
       "                                  OverallCommentLemmatised  \\\n",
       "respid2                                                      \n",
       "7053157  Was told the issue is more related to gmail th...   \n",
       "6984308  Adieb was great I would recommend him to help ...   \n",
       "6980586                                             xyxyxz   \n",
       "6789897   Appreciate his quick and knowledgeable response.   \n",
       "6896172  Ricky finished with his prior appt so he took ...   \n",
       "\n",
       "         OverallCommentPolarity  OverallCommentSubjectivity  \n",
       "respid2                                                      \n",
       "7053157                0.250000                        0.45  \n",
       "6984308                0.800000                        0.75  \n",
       "6980586                0.000000                        0.00  \n",
       "6789897                0.333333                        0.50  \n",
       "6896172                0.050000                        0.15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required Libraries \n",
    "\n",
    "import torch \n",
    "import numpy as np \n",
    "import os \n",
    "import random\n",
    "import pandas as pd \n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.model_selection import train_test_split \n",
    "from transformers import BertTokenizer \n",
    "from torch.utils.data import TensorDataset \n",
    "from transformers import BertForSequenceClassification \n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "#Loading data from Google drive \n",
    "#from google.colab import drive \n",
    "#drive.mount('/content/drive') \n",
    "#os.chdir(\"ENTER LOCATION WHERE DATASET IS.\") # EXAMPLE: /content/drive/My Drive/Sentiment_analysis_using_BERT \n",
    "\n",
    "device = torch.device('cpu')\n",
    "#\n",
    "if torch.cuda.is_available() and device == 'cuda':\n",
    "    device = torch.device('cuda')\n",
    "elif torch.has_mps:\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "print(f'Device is: {device}')\n",
    "df = pd.read_csv('../data/clean/NPS_NATL_subset.csv')\n",
    "\n",
    "df.set_index('respid2', inplace = True) \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10017\n",
       "2     8901\n",
       "1     7785\n",
       "Name: NPS_Code, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NPS_Code.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Workforce</th>\n",
       "      <th>NPS® Breakdown</th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "      <th>NPSCommentLemmatised</th>\n",
       "      <th>NPSCommentPolarity</th>\n",
       "      <th>NPSCommentSubjectivity</th>\n",
       "      <th>OverallCommentCleaned</th>\n",
       "      <th>OverallCommentLemmatised</th>\n",
       "      <th>OverallCommentPolarity</th>\n",
       "      <th>OverallCommentSubjectivity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7053157</th>\n",
       "      <td>1763</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>staff in store in person close by when need them</td>\n",
       "      <td>Staff in store, in person, close by when I nee...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>was told the issue is more related to gmail th...</td>\n",
       "      <td>Was told the issue is more related to gmail th...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984308</th>\n",
       "      <td>832</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>adieb anbari was beyond helpful he answered al...</td>\n",
       "      <td>Adieb Anbari was beyond helpful . He answered ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>adieb was great would recommend him to help an...</td>\n",
       "      <td>Adieb was great I would recommend him to help ...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6980586</th>\n",
       "      <td>288</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>quick and knowledgeable</td>\n",
       "      <td>Quick and knowledgeable</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789897</th>\n",
       "      <td>168</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>he called back quickly within minutes and was ...</td>\n",
       "      <td>He called back quickly (within 5 minutes) and ...</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>appreciate his quick and knowledgeable response</td>\n",
       "      <td>Appreciate his quick and knowledgeable response.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896172</th>\n",
       "      <td>836</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>2</td>\n",
       "      <td>had really good experience thanks to your tech...</td>\n",
       "      <td>I had a really good experience thanks to your ...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>ricky finished with his prior appt so he took ...</td>\n",
       "      <td>Ricky finished with his prior appt so he took ...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Location Workforce NPS® Breakdown  NPS_Code  \\\n",
       "respid2                                                \n",
       "7053157      1763  Precinct       Promoter         2   \n",
       "6984308       832  Precinct       Promoter         2   \n",
       "6980586       288  Precinct       Promoter         2   \n",
       "6789897       168  Precinct       Promoter         2   \n",
       "6896172       836  Precinct       Promoter         2   \n",
       "\n",
       "                                         NPSCommentCleaned  \\\n",
       "respid2                                                      \n",
       "7053157   staff in store in person close by when need them   \n",
       "6984308  adieb anbari was beyond helpful he answered al...   \n",
       "6980586                            quick and knowledgeable   \n",
       "6789897  he called back quickly within minutes and was ...   \n",
       "6896172  had really good experience thanks to your tech...   \n",
       "\n",
       "                                      NPSCommentLemmatised  \\\n",
       "respid2                                                      \n",
       "7053157  Staff in store, in person, close by when I nee...   \n",
       "6984308  Adieb Anbari was beyond helpful . He answered ...   \n",
       "6980586                            Quick and knowledgeable   \n",
       "6789897  He called back quickly (within 5 minutes) and ...   \n",
       "6896172  I had a really good experience thanks to your ...   \n",
       "\n",
       "         NPSCommentPolarity  NPSCommentSubjectivity  \\\n",
       "respid2                                               \n",
       "7053157            0.000000                0.000000   \n",
       "6984308            0.100000                0.600000   \n",
       "6980586            0.333333                0.500000   \n",
       "6789897            0.414444                0.426667   \n",
       "6896172            0.450000                0.400000   \n",
       "\n",
       "                                     OverallCommentCleaned  \\\n",
       "respid2                                                      \n",
       "7053157  was told the issue is more related to gmail th...   \n",
       "6984308  adieb was great would recommend him to help an...   \n",
       "6980586                                             xyxyxz   \n",
       "6789897    appreciate his quick and knowledgeable response   \n",
       "6896172  ricky finished with his prior appt so he took ...   \n",
       "\n",
       "                                  OverallCommentLemmatised  \\\n",
       "respid2                                                      \n",
       "7053157  Was told the issue is more related to gmail th...   \n",
       "6984308  Adieb was great I would recommend him to help ...   \n",
       "6980586                                             xyxyxz   \n",
       "6789897   Appreciate his quick and knowledgeable response.   \n",
       "6896172  Ricky finished with his prior appt so he took ...   \n",
       "\n",
       "         OverallCommentPolarity  OverallCommentSubjectivity  \n",
       "respid2                                                      \n",
       "7053157                0.250000                        0.45  \n",
       "6984308                0.800000                        0.75  \n",
       "6980586                0.000000                        0.00  \n",
       "6789897                0.333333                        0.50  \n",
       "6896172                0.050000                        0.15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respid2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7053157</th>\n",
       "      <td>2</td>\n",
       "      <td>staff in store in person close by when need them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984308</th>\n",
       "      <td>2</td>\n",
       "      <td>adieb anbari was beyond helpful he answered al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6980586</th>\n",
       "      <td>2</td>\n",
       "      <td>quick and knowledgeable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789897</th>\n",
       "      <td>2</td>\n",
       "      <td>he called back quickly within minutes and was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896172</th>\n",
       "      <td>2</td>\n",
       "      <td>had really good experience thanks to your tech...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "respid2                                                          \n",
       "7053157      2   staff in store in person close by when need them\n",
       "6984308      2  adieb anbari was beyond helpful he answered al...\n",
       "6980586      2                            quick and knowledgeable\n",
       "6789897      2  he called back quickly within minutes and was ...\n",
       "6896172      2  had really good experience thanks to your tech..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.NPS_Code.unique()\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "df['label'] = df.NPS_Code.copy()\n",
    "df['text'] = df['NPSCommentCleaned'].astype(str)\n",
    "df = df.filter(['respid', 'label', 'text'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron did great job taking me ahead of my appointment and solved my problem</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron was helpful at checkin and barry was pleasant and knowledgeable at checkout</th>\n",
       "      <th>1</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abby was very helpful and informative</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdullah bhatti who helped me was very helpful and accommodating in fixing my membership which was not in the system although had receipt showing my payment he also resolved the issue with my laptop and explained clearly what caused the problem</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability to help with serious scam that that affected my bank account</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero help with problem purchase</th>\n",
       "      <th>0</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero transparency was promised days took almost days to get my phone back</th>\n",
       "      <th>0</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoe is always pleasure to deal with always knowledgeable and always right</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoey was pleasure to work with she was extremely knowledgeable and showed great customer service skills</th>\n",
       "      <th>2</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çompletely different tech opinions from two techs on two different days</th>\n",
       "      <th>0</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25083 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(aaron did great job taking me ahead of my appointment and solved my problem, 2, train), (aaron was helpful at checkin and barry was pleasant and knowledgeable at checkout, 1, train), (abby was very helpful and informative, 2, train), (abdullah bhatti who helped me was very helpful and accommodating in fixing my membership which was not in the system although had receipt showing my payment he also resolved the issue with my laptop and explained clearly what caused the problem, 2, train), (ability to help with serious scam that that affected my bank account, 2, train), (ability to walk in speak to tech, 1, train), (able to get help the systems were down so spent almost hours in store and was turned away by manager stating his system is down so he help me why are you an apple service center if you help with apple equipment, 0, train), (able to get the work that wanted done, 0, train), (able to have my car radio installed at my appointed time not enough time was allotted to complete job so needed to reschedule after drove minutes to get there, 0, train), (able to make an appointment within hrs and the tech was able to fix it in an hour, 1, train), (able to reset to factory standards while waited just what needed, 2, train), (able to resolve my phone issue, 0, train), (able to schedule convenient time in short time frame part of customer service was excellent, 1, train), (about hrs after got this home it ran into problem and had to shut down and then the same old screen that has been popping up ever since got this thing no hard drive someone should really look at the history on this and just return my money dont understand this will not ever spend one more dollar at best buy, 0, val), (above average, 1, train), (absolute waste of time didnt need an appt because those that didnt make one were ahead of us only way they would repair is if we paid, 0, train), (absolutely awful experience from missing parts too poor poor install lack of knowledge on the installers ruined my rear window and much more, 0, val), (absolutely great, 2, train), (absolutely horrendous service some of the worst ever experienced they have no clue of what they are doing or how to handle customers the phone line which is supposed to help me to contact the store half of the time sends me to corporate have no idea happening with my computer no organization no communication no information and gotten no calls back will never use this embarrassing awful service again it left me so stressed and frustrated, 0, val), (absolutely horrible brought my phone in for battery replacement had an appointment for got it dropped off finally at was told it would be ready at get call at saying they just started then get call at saying they have broken my phone completely they tell me no why if getting my data back or anything the phone is completely broken they tell me to replace my phone take week for one to come in and give me an iphone as loaner then the iphone work go back and at first they refuse to give me my old phone back my property after talking to them multiple times they finally give it back take the phone to repair shop the next day and within mins and my phone is working completely fine with new battery, 0, train), (absolutely horrible knowledge of computers, 0, train), (absolutely horrific company overall it is impossible to reach anyone best buy has it rigged so that you can never ever call anyone in store in your area, 0, train), (absolutely loved the instore service but trying to get information or correct mistakes for the appointment beforehand was impossible am normally very calm with customer service reps but by the fifth hourlong call was practically in tears and some blessed soul finally gave me the direct extension of the store once spoke with tech at the stores physical location again it was phone call that answered all my questions appointment was quick and easy but do not go through the regular customer service or else just demand store until you get it because doing it any other way is impossible, 0, train), (absolutely nothing talked to the tech about was handled purchased the protection for the specific purpose of having my computer cleaned and diagnosed was contacted saying the pc was ready for pick up upon arrival found the computer had not been cleaned or even opened as far as could tell the diagnostic was completely pointless specifically outlined the exact circumstances that caused the problem was having and no effort was made to replicate those circumstances according to the report written by the tech who serviced the computer upon arriving and asking why the computer wasnt cleaned they took it back and had to wait another minutes while they hastily did half asked job of cleaning some of the visible dirt some completely understand that geek squad like every other business is understaffed but your company is selling product it apparently cannot provide and that is the companys fault not the few employees struggling to make ends meet do better, 0, train), (absolutely pleased from intake to pickup, 2, train), (absolutely ridiculous wait time, 0, train), (absolutely the worst experience and far worse than could have expected with even the lowest expectations, 0, train), (absolutely the worst experience ive ever had with geek squad, 0, train), (absolutely worst experience of my life will tell everyone know to stay away from this incompetent company, 0, train), (absolutely zero transparency in the process status was repairing or fixing or whatever the entire time even though my understanding was that you shipped it to apple for repairs no notifications about shipping or anything, 0, train), (abuse at the counter, 0, train), (accidentally wiped my computer clean recovery has not been good geek squad has had my computer for weeks, 0, train), (accomplished my requests, 2, train), (accomplished recovering my data didnt think we could, 1, train), (accomplished what needed with the help of justin, 2, train), (accurate communication via emai, 0, train), (acer case cover screws not installed had ssd installed connector not plugged into motherboard, 0, train), (acknowledge customer and attend to their needs, 2, train), (actual charges should have been clarified before work was done, 1, train), (actual repair experience was very good working my way through the phone process was to make the appointment was, 1, train), (actual service is excellent the wait time for an appointment is rediculusly long what am paying for, 1, train), (actually not because of this experiencethis time they were above what expected but previously would have given you all or so, 1, train), (actually talking to the technician who fixed the product was fine but there was lack of communication between the consultant and technician that made the consultant feel bit useless and fishy they know too much about technology and seemed only to want me to pay for diagnosis and fix really care to hear about my issue, 0, train), (adam and arik have been very helpful, 2, train), (adam rose was incredibly helpful and did great job with the install, 2, val), (adam set up my tablet but when got home couldnt get it to connect told him do not like google have an aol account and use bing and everything was google have been trying to get this tablet to work but have not been successful will be in to return it and stick to my old hp which have had rejuvenated for lack of better expression am not from this generation and that has not been plus either thank you laurie, 0, val), (adam the geek squad technician lacked social interaction skills he didnt know where to find the storage on my computer to help me determine what could get rid of to free up disk space this was the whole reason was there when asked about external hard drives he just pointed to the section of the store that housed them had to ask him to walk me over there and suggest one to use based on my interaction with him he shouldnt be customer facing perhaps he is good with computers behind the scenes, 0, train), (adam valles was great but geek squad was understaffed had appt still waited minutes, 1, train), (adam was exceptionally helpful appreciated his time with me he make me feel he was rushing me out, 2, train), (adam was fantastic and so informative will definitely bring my vehicles here for future services, 2, train), (adam was more than helpful, 2, val), (address book not on new computer, 0, train), (addressed resolved issue with my laptop efficiently and quickly, 2, train), (adequate, 1, train), (adequate but not superior, 1, train), (adequate service issue ultimately remained unknown, 1, train), (adequately pleased with staffservice, 1, train), (adieb anbari was beyond helpful he answered all my questions got me in and out of there as fast as possible and even entertained my year old by answering all her questions and making boat out of paper for her, 2, train), (adieb was very patientknowledgeable and efficient, 1, train), (adil was professional goaloriented answered questions so could understand gave me opportunities to it for provided thoughtful helpful comments appreciated his time, 2, train), (admire the work crew passion on getting the job done right, 1, train), (adrian and gregory tobi were outstanding, 2, train), (adrian arcibeque was very and knowledgeable was respectful and helpful if go back will ask for him again, 2, train), (adroit and friendly, 1, train), (advise was effective, 1, train), (advisor did not appear to be skilled in ms office or related issues, 0, train), (after agents one who disconnected me another who had finished working and didnt notify me left everything on the computer and wiped out my edge an google finally got carla who was extremely personal and knowledgeable had things up and running in about hour was on this fix for over hours, 0, train), (after all of the communication had over the phone and the work done, 0, train), (after an hour of the repair my device stopped working, 0, train), (after appoint day before when we arrived at our appointed time we were told the appointment would be shortened due to sick personnel we had planned upon pickup question session ahead when the appointment was made to our disappointment were advised time allows would made short the manager did agee to address questions with shortened time, 1, val), (after attempts in the store on loop in denton texas with scheduled appointment another without an appointment and this final visit without an appointment was able to receive help and solution was provided he was courteous and explained how things worked and peek tech times to avoid, 1, val), (after awaiting weeks for my laptop to be returned was emailed awaiting parts parts came in computer was being sent back to store then after all that was told unit was unrepairable, 1, train), (after beating dead horse with setup request and paying for it when took my computer home it was not completely setup and spent hours getting the computer to what requested from geek squad yet to have time with geek squad where get back computer and what was agreed on actually takes place, 0, train), (after being on the line for more than hours neither request was completed finally figured out the printer issue on my own it was very difficult to understand the person was talking with am still having difficulty connecting to my second printer, 0, train), (after bringing in my computer tower new printer they could not get my printer to work properlythey wanted to arrange person to come to my house to to do complete system checkat additional chargethere was no charge for in store care, 0, train), (after brought my desktop home noticed loose screw or something rattling around and my side cover is loose, 0, train), (after buying my new computer and having them restore my personal files to it the turn around time took only one day find that to be oustanding, 2, train), (after buying new computer and scheduling setup drove back into town two hour trip but nothing was done because they messed up and said they find my pin it was right on the documents they created then twice my scheduled tech appointment person was not in and the person who helped me was not very helpful, 0, train), (after buying two computers and being at the store every day we still dont have them after five days and they cant tell us when we will get them, 0, train), (after calling the geek squad two times and getting hung up on once was told that had to bring my computer in to get my audio issue resolved when arrived at the store for my appointment waited in line for ten minutes past my appt the person was not very helpful basically he said it would be for them to fix my computer since my plan only covered phone service he was not friendly and said very few words to me reluctantly left my computer couple days later was told the store people could not fix my audio issue and that they would have to send it out and it would cost at least said would just pick up the computer on went to the store as they said did not need an appt to pick it up once got to the store stood in line while four people helped one customer eventually rep called me over he was very curt and did not seem interested in helping me it took him several minutes to find my computer and then when asked him if an external microphone might solve my issue he excused himself thought he was checking on this for me only to find out that he just wanted to commiserate with fellow employee about the last customer the one that four employees were helping when he returned to me he forgot what we were even doing told him happy he apoooguzed then left again to find out if the mic would work on my computer another person came over and said it would so bought the mic and it work it was the worse customer service ever that is why will not recommend geek squad am so disappointed, 0, train), (after charging me to send it out your people didnt fix my computer and did not communicate why when tried to call the store couldnt the phones go to some random number in another country where they would repeatedly transfer my calls and lie to me this has happened with four different computers of ours just gave up with the other three and had to buy my kids new computer this time plan on going to social media for help it may do nothing but maybe can get geeksqusdbestbuy to understand they need humans who have been trained start understanding that your company lies and sucks, 0, train), (after computer go pro big screen tv between my mother in law and myself will no longer give best buy dime my last computer died after months to bad and so sad for me canceled my geek squad supportwas not that happy with phone support anyway as had to spend an hour on the phone just to be told someone would call me back feel was burned on the dell insparon and once is shame on you and twice is shame on me, 0, train), (after consultation was told to purchase speakers but it turned out to be the radio, 0, train), (after days with geek squad and multiple drives back and forth to store miles from my house my computer work as well as it did before started, 0, train), (after detailing my problem to techs at different sites they were confident the problem could be resolved paid and was told that if there were any issues with the hard drive would receive call never received call but instead received an email stating my device was ready for pickup when picked it up the hard drive was out of the laptop and was told it wasnt fixable again never received call the tech who worked on it wasnt available to discuss anything with me was told they could send it out to another level and would get discount so paid for nothing and now they wanted more money from me its not right was never told there was an issue of any kind the person told me that they did see note in the computer stating that they needed to call me if there were any issues couldve used those towards new laptop instead dont even get any of that money back again its not right they took to take my laptop apart and do nothing things should be different maybe pay something have them take look at what the issue is and let the customer know so that decision can be made moving forward with pricing and services needed feel scammed and still need laptop wont be from best buy, 0, train), (after geek squad transferred information email did not work no apps were transferred webroot was not installed these are the noticeable problems how many more will show up in time, 0, train), (after getting my computer serviced with geek squad returned home to find that my computer no longer would hook up to the internet something was not loaded properly during the servicing have to return to the store to get it fixed, 0, train), (after getting the computer home and hooked up we found that much of our information was not included in the transfer of hard drive information, 0, train), (after got home found cannot get into my accounts like my amazon my bank account etc will have to make an appointment to see the geek squad again, 0, train), (after got my airpods back after at least week did not receive my ear tips back the employees at best buy shrugged their shoulders and told me could buy more from apple terrible experience, 0, val), (after got my computer home as far as could tell nothing had been done figured it out on my own, 0, train), (after having an appointment we still had to wait minutes also we get home with the cords so we use the laptop and we live minutes away, 1, train), (after having my computer messed up by the geek squad online brought it personally to the geek squad at best buy store and received exceptional treatment by the retail manager and buy staff member the geek squad, 1, train), (after having my earpods sent out for repair only to find out after exchanging them for replacement to still have the same issue was unacceptable, 1, train), (after having some issues with my previuos visits met bryan he was outstanding and took the time to get me set up, 2, train), (after having the geek squad remote into my pc to correct the problem was facing just to have them leave without doing so and eventually taking my pc to the local best buy so they could work on the actual pc and keeping it for days and advising me that it was repaired only to find out that it was not when got it home and tried to startup the program that they told me they had working only to have it give me an error the service have gotten over the last month from the geek squad has me seriously reconsidering renewing my own membership much less recommending it to someone else, 1, val), (after having two separate automobiles serviced at the audio installation thru total tech was informed that since didnt purchase my audio equipment from bb would have to pay premium labor to have my stuff installed, 0, train), (after having very difficult experience with word and the curser not enabling single spacing with new document your staff searched for about an hour to find the option that has been inadvertently checked, 1, train), (after hours we went home with nothng, 0, train), (after inhome visits by nice geek squad guys trips by me to best buy and numerous phone calls with people could not understand lost count my issue was not resolved had to tell my very long story to different person each time called it was emotionally and physically draining after weeks of trying to get geek squad to help me with my problem someone finally transferred me to apple care they solved my issue, 0, train), ...]\n",
       "\n",
       "[25083 rows x 0 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.label.values, test_size=0.15, random_state=17, stratify=df.label.values) \n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]   #CREATING A NEW COLUMN IN DATASET AND SETTING ALL VALUES TO 'not_set' \n",
    "\n",
    "df.loc[X_train, 'data_type'] ='train' #CHECKING AND SETTING data_type TO TRAIN \n",
    "df.loc[X_val, 'data_type'] = 'val' #CHECKING AND SETTING data_type TO VAL\n",
    "\n",
    "\n",
    "df.groupby(['text', 'label', 'data_type']).count() #TO CHECK WHICH CATEGORY DATA IS IN WHICH data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "#ENCODING DATA\n",
    "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type=='train'].text.values,\n",
    "                                                add_special_tokens=True,\n",
    "                                                return_attention_mask=True,\n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                max_length=256,\n",
    "                                                 return_tensors='pt'\n",
    "                                                )\n",
    "encoded_data_val = tokenizer.batch_encode_plus(df[df.data_type=='val'].text.values,\n",
    "                                                add_special_tokens=True,\n",
    "                                                return_attention_mask=True,\n",
    "                                                truncation=True,\n",
    "                                                padding='max_length',\n",
    "                                                max_length=256,\n",
    "                                                 return_tensors='pt'\n",
    "                                                )\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#SETTING MODEL\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3, output_attentions=False, output_hidden_states=False )\n",
    "model.to(device)\n",
    "#CREATING DATA LOADERS\n",
    "dataloader_train = DataLoader(dataset_train,sampler = RandomSampler(dataset_train), batch_size= 32)\n",
    "dataloader_val = DataLoader(dataset_val, sampler = RandomSampler(dataset_val), batch_size= 32)\n",
    "      \n",
    "\n",
    "#SETTING OPTIMIZERS\n",
    "\n",
    "op = AdamW(model.parameters(),lr=1e-5,eps=1e-8)\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(op, num_warmup_steps=10, num_training_steps=len(dataloader_train)*epochs)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO CALCULATE F1 SCORE\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')\n",
    "\n",
    "#FUNCTION FOR CALCULATING ACCURACY PER CLASS\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v:k for k,v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(label_dict_inverse[label])\n",
    "        print(\"accuracy \", len(y_preds[y_preds==label])/len(y_true))\n",
    "\n",
    "#FUNCTION FOR MODEL EVALUATION\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    result_np = []\n",
    "    \"\"\"\n",
    "    inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_data = tokenizer.encode_plus(text = sentence,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            truncation=True,\n",
    "                                            padding='max_length',\n",
    "                                            max_length=256,\n",
    "                                            return_tensors='pt'\n",
    "                                            )\n",
    "\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    outputs = model(encoded_data)\n",
    "    logits = outputs[1]\n",
    "    pred = np.argmax(logits, axis = 1)\n",
    "    # print(classification_report(test_y, pred))\n",
    "    return(pred)\n",
    "\n",
    "    \n",
    "    #labels_train = torch.tensor(df[df.data_type=='train'].label.values)    \n",
    "    \"\"\"\n",
    "    img = test_images[idx, :, :, :]\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = torch.Tensor(img).permute(0, 3, 1, 2).to(device)\n",
    "    # print(img.shape)\n",
    "    pred = self(img)\n",
    "    pred_np = pred.cpu().detach().numpy()\n",
    "    for elem in pred_np:\n",
    "        result_np.append(elem)\n",
    "    \"\"\"\n",
    "    return result_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd908363e7d49f784073eaade8d660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4862094fa542db8ca2e03713ac0687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/suchanek/Library/Mobile Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000009?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000009?line=20'>21</a>\u001b[0m loss_train_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000009?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000009?line=22'>23</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000009?line=24'>25</a>\u001b[0m op\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/aigpu/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/aigpu/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm(range(1, 2)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc ='Epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                       disable=False\n",
    "                       )\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = { 'input_ids' : batch[0],\n",
    "                 'attention_mask' : batch[1],\n",
    "                 'labels' : batch[2]\n",
    "                 }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        op.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch))})\n",
    "    \n",
    "    # THIS SECTION OF CODE IS JUST FOR PRINTING VALUES AFTER EACH EPOCH.\n",
    "    torch.save(model.state_dict(), f'BERT_ft_epoch{epoch}.model')\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    \n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 score (weighted): {val_f1}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "accuracy  0.825016633399867\n",
      "1\n",
      "accuracy  0.2996575342465753\n",
      "0\n",
      "accuracy  0.9131086142322098\n"
     ]
    }
   ],
   "source": [
    "_, predictions, true_val = evaluate(dataloader_val)  #why _ ? reason behind this is evaluate function return 3 values and i don't require the 1st value i.e., loss_val_avg\n",
    "\n",
    "accuracy_per_class(predictions, true_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:246\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[item]\n\u001b[1;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/suchanek/Library/Mobile Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000013?line=0'>1</a>\u001b[0m predict(model, \u001b[39m\"\u001b[39;49m\u001b[39mThis is a terrible experience\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/suchanek/Library/Mobile Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb Cell 9'\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, sentence)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=14'>15</a>\u001b[0m input_ids \u001b[39m=\u001b[39m encoded_data[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=15'>16</a>\u001b[0m attention_masks \u001b[39m=\u001b[39m encoded_data[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=16'>17</a>\u001b[0m pred \u001b[39m=\u001b[39m model(encoded_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=17'>18</a>\u001b[0m \u001b[39m#labels_train = torch.tensor(df[df.data_type=='train'].label.values)    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=19'>20</a>\u001b[0m \u001b[39mimg = test_images[idx, :, :, :]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=20'>21</a>\u001b[0m \u001b[39mimg = np.expand_dims(img, axis=0)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=26'>27</a>\u001b[0m \u001b[39m    result_np.append(elem)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_Bert2.ipynb#ch0000012?line=27'>28</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1545\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1539\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1545\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1546\u001b[0m     input_ids,\n\u001b[1;32m   1547\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1548\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1549\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1550\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1551\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1552\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1553\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1554\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1555\u001b[0m )\n\u001b[1;32m   1557\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1559\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1130\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1131\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1132\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:944\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    943\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49msize()\n\u001b[1;32m    945\u001b[0m \u001b[39melif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    946\u001b[0m     input_shape \u001b[39m=\u001b[39m inputs_embeds\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:248\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[item]\n\u001b[1;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict(model, \"This is a terrible experience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './BertModels/BERT_FT_epoch8.model'\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the tokenizer of the \"bert-base-cased\" pretrained model\n",
    "# See https://huggingface.co/transformers/pretrained_models.html for other models\n",
    "tz = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# The senetence to be encoded\n",
    "sent = \"Let's learn deep learning!\"\n",
    "\n",
    "# Encode the sentence\n",
    "encoded = tz.encode_plus(\n",
    "    text=sent,  # the sentence to be encoded\n",
    "    add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "    max_length = 64,  # maximum length of a sentence\n",
    "    pad_to_max_length=True,  # Add [PAD]s\n",
    "    return_attention_mask = True,  # Generate the attention mask\n",
    "    return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Get the input IDs and attention mask in tensor format\n",
    "input_ids = encoded['input_ids']\n",
    "attn_mask = encoded['attention_mask']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('aigpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ee8fbf491c2dc09f1850242389295773ac6375f10ce9efdb2142efbd90a9151"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
