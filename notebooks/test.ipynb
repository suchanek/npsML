{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BBY stuff\n",
    "import bby\n",
    "import bby.util as ut\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tensorflow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "import wordcloud\n",
    "from collections import Counter\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#from bby import replacers as rep\n",
    "from bby.util import nps_cleanstring, nps_lemmatise, lemma_remove_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "# given an input string, remove stopwords, and words longer than 1 char\n",
    "import string\n",
    "def clean_commentlist(commentlist):\n",
    "    res = list()\n",
    "    for i in range(len(commentlist)):\n",
    "        cstr = commentlist[i]\n",
    "        res.append(ut.nps_cleanstring(cstr))\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erics computer ssss oi fk fk awesome aweosme done eric is very fine young man with manly ways he\n",
      "erics computer sss oi fk fk awesome aweosme do eric be very fine young man with manly way he\n",
      "Erics computer sss awesome AWEOSME do Eric fine young manly way\n",
      "serics computer less of ff ff awesome aweosme done eric is very fine young man with manly ways he\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "dirty = \"Eric's computer 'ssss oi!@#$@!@# fk~~ fk! awesome!!! AWEOSME!@#$ `done` Eric is a very fine young man with manly ways. HE\"\n",
    "res = nps_cleanstring(dirty)\n",
    "print(res)\n",
    "res1 = nps_lemmatise(res)\n",
    "print(res1)\n",
    "res2 = lemma_remove_stopwords(dirty)\n",
    "print(res2)\n",
    "tb = TextBlob(res)\n",
    "res3 = tb.correct()\n",
    "print(res3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "all_path = \"../data/clean/NPS_Natl_cleaned_small.csv\"\n",
    "all_path = \"../data/raw/export_natl_small.xlsx\"\n",
    "\n",
    "NPS_df = pd.read_excel(all_path, header=4)\n",
    "\n",
    "NPS_df.head(5)\n",
    "nps_comments = NPS_df['NPS® Comment'].fillna('xyzxzy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bby.util import lemma_remove_stopwords\n",
    "from bby.util import nps_cleanstring, nps_lemmatise\n",
    "comments = NPS_df['NPS® Comment']\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "NPS_df['NPSCommentCleaned'] = nps_comments.apply(nps_cleanstring)\n",
    "NPS_df['NPSCommentLemmatised'] = nps_comments.apply(nps_lemmatise)\n",
    "\n",
    "\n",
    "\n",
    "#cleanstring = olemma_remove_stopwords(comments)\n",
    "#print(cleanstring)\n",
    "\n",
    "#cleanstring2 = cleanup_data(comments)\n",
    "#print(cleanstring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime.datetime as dt\n",
    "start = dt.now()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im = Image.open(\"logo.png\")\n",
    "bg_pic = np.asarray(im)\n",
    "wc = WordCloud(mask=bg_pic, background_color='white', width = 300, height=300, margin=2)\n",
    "text = '''\n",
    "\n",
    "'''\n",
    "wc.generate(text)\n",
    "wc.to_file('wc1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define data\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "y = [8, 13, 14, 11, 16, 22]\n",
    "\n",
    "#create scatterplot with axis labels\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('X Variable')\n",
    "plt.ylabel('Y Variable')\n",
    "\n",
    "#save figure to PNG file\n",
    "plt.savefig('my_plot.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python aigpu)",
   "language": "python",
   "name": "aigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
