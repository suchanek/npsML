{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet analysis using BERT\n",
    "# https://medium.com/@hajar.zankadi/using-bertopic-and-bertweet-transformer-to-predict-interest-tag-from-tweets-67189f11b992\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 14:56:38,254 : INFO : Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-06-14 14:56:38,255 : INFO : NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# import tweet preprocessor\n",
    "import preprocessor as p\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "data_tweet= pd.read_csv('../data/clean/NPS_NATL_subset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Workforce</th>\n",
       "      <th>NPS® Breakdown</th>\n",
       "      <th>respid2</th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "      <th>NPSCommentLemmatised</th>\n",
       "      <th>NPSCommentPolarity</th>\n",
       "      <th>NPSCommentSubjectivity</th>\n",
       "      <th>OverallCommentCleaned</th>\n",
       "      <th>OverallCommentLemmatised</th>\n",
       "      <th>OverallCommentPolarity</th>\n",
       "      <th>OverallCommentSubjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>6702347</td>\n",
       "      <td>2</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "      <td>Because the representative listened to my conc...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>did great work</td>\n",
       "      <td>Did great work</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>6589878</td>\n",
       "      <td>2</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "      <td>They're so helpful and knowledgable</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>katelyn feliciano was so wonderful she was war...</td>\n",
       "      <td>Katelyn Feliciano was so wonderful . She was w...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>6691534</td>\n",
       "      <td>2</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "      <td>The service I requested was preformed quickly ...</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>xyxyxz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377</td>\n",
       "      <td>Autotech</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>7017148</td>\n",
       "      <td>2</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "      <td>Cody Mitchell is absolutely amazing . He's ver...</td>\n",
       "      <td>0.444082</td>\n",
       "      <td>0.730658</td>\n",
       "      <td>cody has been absolutely amazing and consider ...</td>\n",
       "      <td>Cody has been absolutely amazing and I conside...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216</td>\n",
       "      <td>Precinct</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>6794996</td>\n",
       "      <td>2</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "      <td>The careful attention provided by tech staff.</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>responsive and respectful</td>\n",
       "      <td>Responsive and respectful.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location Workforce NPS® Breakdown  respid2  NPS_Code  \\\n",
       "0      1224  Precinct       Promoter  6702347         2   \n",
       "1       129  Precinct       Promoter  6589878         2   \n",
       "2       247  Precinct       Promoter  6691534         2   \n",
       "3       377  Autotech       Promoter  7017148         2   \n",
       "4       216  Precinct       Promoter  6794996         2   \n",
       "\n",
       "                                   NPSCommentCleaned  \\\n",
       "0  because the representative listened to my conc...   \n",
       "1                 theyre so helpful and knowledgable   \n",
       "2  the service requested was preformed quickly an...   \n",
       "3  cody mitchell is absolutely amazing hes very s...   \n",
       "4       the careful attention provided by tech staff   \n",
       "\n",
       "                                NPSCommentLemmatised  NPSCommentPolarity  \\\n",
       "0  Because the representative listened to my conc...            0.000000   \n",
       "1                They're so helpful and knowledgable            0.000000   \n",
       "2  The service I requested was preformed quickly ...            0.354167   \n",
       "3  Cody Mitchell is absolutely amazing . He's ver...            0.444082   \n",
       "4      The careful attention provided by tech staff.           -0.100000   \n",
       "\n",
       "   NPSCommentSubjectivity                              OverallCommentCleaned  \\\n",
       "0                0.000000                                     did great work   \n",
       "1                0.000000  katelyn feliciano was so wonderful she was war...   \n",
       "2                0.500000                                             xyxyxz   \n",
       "3                0.730658  cody has been absolutely amazing and consider ...   \n",
       "4                1.000000                          responsive and respectful   \n",
       "\n",
       "                            OverallCommentLemmatised  OverallCommentPolarity  \\\n",
       "0                                     Did great work                     0.8   \n",
       "1  Katelyn Feliciano was so wonderful . She was w...                     0.6   \n",
       "2                                             xyxyxz                     0.0   \n",
       "3  Cody has been absolutely amazing and I conside...                     0.8   \n",
       "4                         Responsive and respectful.                     0.5   \n",
       "\n",
       "   OverallCommentSubjectivity  \n",
       "0                    0.750000  \n",
       "1                    0.633333  \n",
       "2                    0.000000  \n",
       "3                    0.600000  \n",
       "4                    0.700000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_tweet.shape\n",
    "data_tweet.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NPS_Code                                  NPSCommentCleaned\n",
       "0         2  because the representative listened to my conc...\n",
       "1         2                 theyre so helpful and knowledgable\n",
       "2         2  the service requested was preformed quickly an...\n",
       "3         2  cody mitchell is absolutely amazing hes very s...\n",
       "4         2       the careful attention provided by tech staff"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet = data_tweet.filter(['NPS_Code','NPSCommentCleaned'], axis=1)\n",
    "\n",
    "#remove duplicates\n",
    "data_tweet=data_tweet.drop_duplicates()\n",
    "data_tweet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#work with a sample of 10000 tweets\n",
    "data = data_tweet.iloc[0:10000]\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NPS_Code                                  NPSCommentCleaned  \\\n",
       "0         2  because the representative listened to my conc...   \n",
       "1         2                 theyre so helpful and knowledgable   \n",
       "2         2  the service requested was preformed quickly an...   \n",
       "3         2  cody mitchell is absolutely amazing hes very s...   \n",
       "4         2       the careful attention provided by tech staff   \n",
       "\n",
       "                                                text  \n",
       "0  because the representative listened to my conc...  \n",
       "1                 theyre so helpful and knowledgable  \n",
       "2  the service requested was preformed quickly an...  \n",
       "3  cody mitchell is absolutely amazing hes very s...  \n",
       "4       the careful attention provided by tech staff  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Customizing the preprocessor to exclude removing hashtags since they are valuable as a rich information\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION,p.OPT.SMILEY,p.OPT.NUMBER )\n",
    "\n",
    "#forming a separate feature for cleaned tweets\n",
    "for i,v in enumerate(data['NPSCommentCleaned']):\n",
    "    data.loc[i,'text'] = p.clean(str(v))\n",
    "    \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#REMOVE ONLY THE '#'NOT THE WORD AFTER\n",
    "def remove_hashtag_sign(text):\n",
    "    text = re.sub(r'#', '', text)\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x:remove_hashtag_sign(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPS_Code</th>\n",
       "      <th>NPSCommentCleaned</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "      <td>because the representative listened to my conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "      <td>theyre so helpful and knowledgable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "      <td>the service requested was preformed quickly an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "      <td>cody mitchell is absolutely amazing hes very s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "      <td>the careful attention provided by tech staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NPS_Code                                  NPSCommentCleaned  \\\n",
       "0         2  because the representative listened to my conc...   \n",
       "1         2                 theyre so helpful and knowledgable   \n",
       "2         2  the service requested was preformed quickly an...   \n",
       "3         2  cody mitchell is absolutely amazing hes very s...   \n",
       "4         2       the careful attention provided by tech staff   \n",
       "\n",
       "                                                text  \n",
       "0  because the representative listened to my conc...  \n",
       "1                 theyre so helpful and knowledgable  \n",
       "2  the service requested was preformed quickly an...  \n",
       "3  cody mitchell is absolutely amazing hes very s...  \n",
       "4       the careful attention provided by tech staff  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Remove extra white spaces, punctuation and apply lower casing\n",
    "data['text'] = data['text'].str.lower().str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prepare tweet list\n",
    "tweet_list = data.text.tolist()\n",
    "\n",
    "#remove english stop words\n",
    "stopwords = stopwords.words('english') \n",
    "\n",
    "#Use CountVectorizer to remove stopwords\n",
    "vectorizer_model = CountVectorizer(stop_words= stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(embedding_model=\"vinai/bertweet-base\", vectorizer_model=vectorizer_model,low_memory=True,calculate_probabilities=True,verbose=True, n_gram_range=(1, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df64ab5daadb4023a240911a80f4a9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/suchanek/Library/Mobile Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_bert1.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/suchanek/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/myML/nps/notebooks/NPS_bert1.ipynb#ch0000009?line=0'>1</a>\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mfit_transform(tweet_list)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py:294\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, y)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=290'>291</a>\u001b[0m \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=291'>292</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m select_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=292'>293</a>\u001b[0m                                           language\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage)\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=293'>294</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_embeddings(documents\u001b[39m.\u001b[39;49mDocument,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=294'>295</a>\u001b[0m                                           method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdocument\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=295'>296</a>\u001b[0m                                           verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=296'>297</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTransformed documents to Embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=297'>298</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py:1362\u001b[0m, in \u001b[0;36mBERTopic._extract_embeddings\u001b[0;34m(self, documents, method, verbose)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1359'>1360</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39membed_words(documents, verbose)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1360'>1361</a>\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1361'>1362</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49membed_documents(documents, verbose)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1362'>1363</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1363'>1364</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong method for extracting document/word embeddings. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/_bertopic.py?line=1364'>1365</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mEither choose \u001b[39m\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as the method. \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py:69\u001b[0m, in \u001b[0;36mBaseEmbedder.embed_documents\u001b[0;34m(self, document, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_documents\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=55'>56</a>\u001b[0m                     document: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=56'>57</a>\u001b[0m                     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=57'>58</a>\u001b[0m     \u001b[39m\"\"\" Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=58'>59</a>\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=59'>60</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=66'>67</a>\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=67'>68</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_base.py?line=68'>69</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(document, verbose)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py:63\u001b[0m, in \u001b[0;36mSentenceTransformerBackend.embed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=49'>50</a>\u001b[0m           documents: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=50'>51</a>\u001b[0m           verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=51'>52</a>\u001b[0m     \u001b[39m\"\"\" Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=52'>53</a>\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=53'>54</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=60'>61</a>\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=61'>62</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=62'>63</a>\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49mencode(documents, show_progress_bar\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/bertopic/backend/_sentencetransformers.py?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:164\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=160'>161</a>\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=162'>163</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=163'>164</a>\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=165'>166</a>\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py?line=166'>167</a>\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=63'>64</a>\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=65'>66</a>\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=66'>67</a>\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py?line=68'>69</a>\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:844\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=836'>837</a>\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=837'>838</a>\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=838'>839</a>\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=839'>840</a>\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=840'>841</a>\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=841'>842</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=843'>844</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=844'>845</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=845'>846</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=846'>847</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=847'>848</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=848'>849</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=849'>850</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=850'>851</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=851'>852</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=852'>853</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=860'>861</a>\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=861'>862</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=862'>863</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:137\u001b[0m, in \u001b[0;36mRobertaEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=134'>135</a>\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=135'>136</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=136'>137</a>\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposition_embeddings(position_ids)\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=137'>138</a>\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py?line=138'>139</a>\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=158'>159</a>\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/modules/sparse.py?line=159'>160</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py:2044\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2037'>2038</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2038'>2039</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2039'>2040</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2040'>2041</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2041'>2042</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2042'>2043</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> <a href='file:///Users/suchanek/miniforge3/envs/ai_m1new/lib/python3.9/site-packages/torch/nn/functional.py?line=2043'>2044</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(tweet_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bert_topics(topic_model, num_topics):\n",
    "    word_dict = {}\n",
    "    for i in range(num_topics):\n",
    "        words=topic_model.get_topic(i)\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "    return pd.DataFrame(word_dict)\n",
    "\n",
    "get_bert_topics(topic_model, len(set(topics))-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_wordcloud(topic_model, topic):\n",
    "    text = {word: value for word, value in topic_model.get_topic(topic)}\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic\"+\" \"+ str(topic))\n",
    "    plt.show()\n",
    " \n",
    "#visualize the top 3 topics\n",
    "for i in range(1,4):\n",
    "    create_wordcloud(topic_model, topic=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = tweet_list\n",
    "# Preprocess Documents\n",
    "documents = pd.DataFrame({\"Document\": docs,\n",
    "                          \"ID\": range(len(docs)),\n",
    "                          \"Topic\": topics})\n",
    "documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "cleaned_docs = topic_model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "# Extract vectorizer and analyzer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "words = vectorizer.get_feature_names()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic) if words!=''] \n",
    "               for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2ae5d3a08a6e204c8c8cee8069ee9bbd2ab88ccb9eee13930db12104613cdbd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
